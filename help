# Clank Backend API Documentation

## Overview

Clank is a backend service that combines graph database operations with Large Language Model (LLM) capabilities. It provides a Neo4j-based graph database for storing entities and relationships, with integrated LLM processing through llama.cpp and Model Context Protocol (MCP) support for advanced tool calling and context injection.

## Architecture Components

- **Graph Database**: Neo4j for storing nodes and relationships
- **LLM Integration**: Direct integration with llama.cpp via OpenAI-compatible API
- **MCP Support**: Model Context Protocol for tool calling and context injection
- **WebSocket Support**: Real-time chat capabilities
- **REST API**: Standard HTTP endpoints for graph operations

## Base URL
```
http://localhost:8080
```

## Core Endpoints

### Health Check
```http
GET /health
```
Returns service health status and llama.cpp connectivity.

**Response:**
```json
{
  "status": "ok",
  "service": "clank-backend",
  "llm_url": "http://localhost:8080",
  "llm_status": "ok"
}
```

### WebSocket Chat
```http
GET /ws
```
WebSocket endpoint for real-time chat with the LLM.

**Message Format:**
```json
{
  "type": "chat",
  "messages": [
    {
      "role": "user",
      "content": "Hello, world!"
    }
  ]
}
```

## LLM Endpoints

### Direct Chat (Non-streaming)
```http
POST /llm/chat
```

**Request Body:**
```json
{
  "messages": [
    {
      "role": "user",
      "content": "Your message here"
    }
  ],
  "model": "optional-model-name",
  "stream": false
}
```

### Streaming Chat
```http
POST /llm/chat/stream
```

**Request Body:**
```json
{
  "messages": [
    {
      "role": "user",
      "content": "Your message here"
    }
  ],
  "stream": true
}
```

Returns Server-Sent Events (SSE) stream.

### MCP-Enhanced Chat
```http
POST /llm/chat/mcp
```

Chat endpoint with MCP tool calling and context injection capabilities.

**Request Body:**
```json
{
  "messages": [
    {
      "role": "user",
      "content": "Analyze the connections between these entities"
    }
  ],
  "stream": true
}
```

### MCP Server-Sent Events
```http
GET /llm/mcp/sse
```

Direct MCP communication via SSE transport.

## Graph Database API

All graph endpoints are prefixed with `/api` and require database connectivity.

### Nodes

#### Get All Nodes
```http
GET /api/nodes
```

#### Create Node
```http
POST /api/node
```

**Request Body:**
```json
{
  "type": "Person",
  "properties": {
    "name": "John Doe",
    "age": 30,
    "occupation": "Developer"
  }
}
```

#### Get Node by ID
```http
GET /api/node/{id}
```

#### Update Node
```http
PUT /api/node/{id}
```

#### Delete Node
```http
DELETE /api/node/{id}
```

#### Search Nodes
```http
GET /api/search?q=searchterm&type=NodeType
```

#### Get Network
```http
GET /api/network
```

Returns the entire graph network with nodes and connections.

### Batch Operations

#### Batch Create Nodes
```http
POST /api/nodes/batch
```

**Request Body:**
```json
[
  {
    "type": "Person",
    "properties": {
      "name": "Alice"
    }
  },
  {
    "type": "Company",
    "properties": {
      "name": "TechCorp"
    }
  }
]
```

#### Batch Delete Nodes
```http
DELETE /api/nodes/batch
```

**Request Body:**
```json
["node-id-1", "node-id-2", "node-id-3"]
```

### Relationships

#### Create Relationship
```http
POST /api/relationship
```

**Request Body:**
```json
{
  "fromId": "node-id-1",
  "toId": "node-id-2",
  "type": "WORKS_FOR",
  "properties": {
    "since": "2020-01-01",
    "position": "Senior Developer"
  }
}
```

#### Get/Update/Delete Relationship
```http
GET /api/relationship/{id}
PUT /api/relationship/{id}
DELETE /api/relationship/{id}
```

### Graph Operations

#### Get Shortest Path
```http
GET /api/path?from=node-id-1&to=node-id-2
```

#### Get Subgraph
```http
GET /api/subgraph/{nodeId}?depth=2
```

### Analytics

#### Corruption Score
```http
GET /api/analytics/corruption-score/{nodeId}
```

Calculates a corruption score based on relationship types and counts.

#### Entity Connections
```http
GET /api/analytics/entity-connections/{nodeId}?depth=3
```

#### Timeline
```http
GET /api/analytics/timeline
```

#### Network Statistics
```http
GET /api/analytics/network-stats
```

## MCP Integration Guide

### Understanding MCP in Clank

MCP (Model Context Protocol) enables your LLM to use tools and access context from your graph database. The integration is handled in `mcp.go`.

### Current MCP Structure

The `MCPService` struct provides:
- Tool calling capabilities
- Context injection from graph database  
- Message preprocessing before sending to LLM

### Adding MCP Tools

To add new MCP tools, you need to extend the MCP implementation. Here's the process:

#### 1. Define Tool Schema

Create a new file `internal/mcp/tools.go`:

```go
package mcp

import (
    "context"
    "encoding/json"
    "fmt"
    "clank/internal/db"
    "clank/internal/models"
    "github.com/modelcontextprotocol/go-sdk/mcp"
)

// Tool definitions
func (s *MCPService) RegisterTools() {
    // Register entity extraction tool
    s.server.RegisterTool(&mcp.Tool{
        Name: "extract_entities",
        Description: "Extract entities and relationships from text",
        InputSchema: map[string]interface{}{
            "type": "object",
            "properties": map[string]interface{}{
                "text": {
                    "type": "string",
                    "description": "The text to analyze",
                },
                "entity_types": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Types of entities to extract (Person, Organization, Location, etc.)",
                },
            },
            "required": []string{"text"},
        },
    }, s.handleEntityExtraction)
    
    // Register graph query tool
    s.server.RegisterTool(&mcp.Tool{
        Name: "query_graph",
        Description: "Query the graph database for related entities",
        InputSchema: map[string]interface{}{
            "type": "object",
            "properties": map[string]interface{}{
                "query": {
                    "type": "string",
                    "description": "Natural language query about relationships",
                },
                "node_id": {
                    "type": "string",
                    "description": "Optional: Focus on a specific node",
                },
            },
            "required": []string{"query"},
        },
    }, s.handleGraphQuery)
}
```

#### 2. Implement Tool Handlers

```go
func (s *MCPService) handleEntityExtraction(ctx context.Context, params map[string]interface{}) (interface{}, error) {
    text, ok := params["text"].(string)
    if !ok {
        return nil, fmt.Errorf("text parameter is required")
    }
    
    // Use LLM to extract entities
    extractionPrompt := fmt.Sprintf(`
    Extract entities and relationships from the following text.
    Return as JSON with entities and relationships arrays.
    
    Text: %s
    
    Format:
    {
      "entities": [
        {"name": "Entity Name", "type": "Person|Organization|Location|Event", "properties": {}}
      ],
      "relationships": [
        {"from": "Entity1", "to": "Entity2", "type": "RELATIONSHIP_TYPE", "properties": {}}
      ]
    }
    `, text)
    
    messages := []Message{
        {Role: "system", Content: "You are an expert entity extraction system."},
        {Role: "user", Content: extractionPrompt},
    }
    
    result, err := s.llmClient.Generate(ctx, messages)
    if err != nil {
        return nil, fmt.Errorf("failed to extract entities: %w", err)
    }
    
    // Parse the LLM response and return structured data
    var extraction struct {
        Entities      []models.Node         `json:"entities"`
        Relationships []models.Relationship `json:"relationships"`
    }
    
    if err := json.Unmarshal([]byte(result.Choices[0].Message.Content), &extraction); err != nil {
        return nil, fmt.Errorf("failed to parse extraction result: %w", err)
    }
    
    return extraction, nil
}

func (s *MCPService) handleGraphQuery(ctx context.Context, params map[string]interface{}) (interface{}, error) {
    query := params["query"].(string)
    
    // Convert natural language to Cypher query using LLM
    cypherPrompt := fmt.Sprintf(`
    Convert this natural language query to a Cypher query for Neo4j:
    "%s"
    
    Return only the Cypher query, no explanation.
    Available node types: Person, Organization, Location, Event
    Available relationship types: WORKS_FOR, LOCATED_IN, PARTICIPATED_IN, CONNECTED_TO
    `, query)
    
    messages := []Message{
        {Role: "system", Content: "You are a Cypher query expert."},
        {Role: "user", Content: cypherPrompt},
    }
    
    result, err := s.llmClient.Generate(ctx, messages)
    if err != nil {
        return nil, fmt.Errorf("failed to generate query: %w", err)
    }
    
    cypherQuery := result.Choices[0].Message.Content
    
    // Execute the query against the graph database
    graphResult, err := db.ExecuteRead(func(tx neo4j.Transaction) (interface{}, error) {
        result, err := tx.Run(cypherQuery, nil)
        if err != nil {
            return nil, err
        }
        
        var records []map[string]interface{}
        for result.Next() {
            records = append(records, result.Record().AsMap())
        }
        
        return records, nil
    })
    
    if err != nil {
        return nil, fmt.Errorf("failed to execute graph query: %w", err)
    }
    
    return graphResult, nil
}
```

#### 3. Update MCP Service

Modify `internal/api/handlers/mcp.go`:

```go
func NewMCPService(cfg *config.Config) *MCPService {
    service := &MCPService{
        llmClient: llm.NewClient(cfg),
    }

    impl := &mcp.Implementation{
        Name:    "clank-llm-proxy",
        Version: "v0.1.0",
    }

    service.server = mcp.NewServer(impl, &mcp.ServerOptions{})
    
    // Register all tools
    service.RegisterTools()

    return service
}
```

### Adding MCP Prompts

#### 1. Create Prompt Templates

Create `internal/mcp/prompts.go`:

```go
package mcp

const (
    EntityExtractionPrompt = `
You are an expert at extracting entities and relationships from text.

Guidelines:
- Extract people, organizations, locations, and events
- Identify relationships between entities
- Include confidence scores and source text spans
- Return structured JSON format

Text to analyze: {{.text}}

Expected entity types: {{.entityTypes}}
`

    RelationshipAnalysisPrompt = `
Analyze the relationships in the following graph context:

Nodes: {{.nodes}}
Relationships: {{.relationships}}

Provide insights about:
- Connection patterns
- Influential entities
- Potential missing relationships
- Anomalies or interesting patterns
`

    CorruptionAnalysisPrompt = `
Given the following entity and their connections, analyze potential corruption indicators:

Entity: {{.entity}}
Relationships: {{.relationships}}
Financial data: {{.financialData}}

Look for:
- Unusual money flows
- Conflicts of interest
- Regulatory violations
- Network effects
`
)
```

#### 2. Create Prompt Service

Create `internal/mcp/prompt_service.go`:

```go
package mcp

import (
    "bytes"
    "text/template"
)

type PromptService struct {
    templates map[string]*template.Template
}

func NewPromptService() *PromptService {
    ps := &PromptService{
        templates: make(map[string]*template.Template),
    }
    
    // Register templates
    ps.templates["entity_extraction"] = template.Must(template.New("entity_extraction").Parse(EntityExtractionPrompt))
    ps.templates["relationship_analysis"] = template.Must(template.New("relationship_analysis").Parse(RelationshipAnalysisPrompt))
    ps.templates["corruption_analysis"] = template.Must(template.New("corruption_analysis").Parse(CorruptionAnalysisPrompt))
    
    return ps
}

func (ps *PromptService) RenderPrompt(name string, data interface{}) (string, error) {
    tmpl, exists := ps.templates[name]
    if !exists {
        return "", fmt.Errorf("prompt template '%s' not found", name)
    }
    
    var buf bytes.Buffer
    if err := tmpl.Execute(&buf, data); err != nil {
        return "", fmt.Errorf("failed to render prompt: %w", err)
    }
    
    return buf.String(), nil
}
```

## Example: News Article Entity Extraction Endpoint

Here's how to create a complete entity extraction endpoint that scrapes news articles and processes them with the LLM:

### 1. Create the Models

Add to `internal/models/extraction.go`:

```go
package models

import "time"

type ArticleExtractionRequest struct {
    URL     string   `json:"url,omitempty"`
    Content string   `json:"content,omitempty"`
    Title   string   `json:"title,omitempty"`
    EntityTypes []string `json:"entity_types,omitempty"`
}

type ArticleExtractionResponse struct {
    Article      ArticleContent    `json:"article"`
    Entities     []ExtractedEntity `json:"entities"`
    Relationships []ExtractedRelationship `json:"relationships"`
    ProcessedAt  time.Time         `json:"processed_at"`
    Confidence   float64           `json:"confidence"`
}

type ArticleContent struct {
    URL     string `json:"url"`
    Title   string `json:"title"`
    Content string `json:"content"`
    Author  string `json:"author,omitempty"`
    Date    string `json:"date,omitempty"`
}

type ExtractedEntity struct {
    Name       string                 `json:"name"`
    Type       string                 `json:"type"`
    Properties map[string]interface{} `json:"properties"`
    Confidence float64                `json:"confidence"`
    SourceSpan string                 `json:"source_span"`
}

type ExtractedRelationship struct {
    From       string                 `json:"from"`
    To         string                 `json:"to"`
    Type       string                 `json:"type"`
    Properties map[string]interface{} `json:"properties"`
    Confidence float64                `json:"confidence"`
    Context    string                 `json:"context"`
}
```

### 2. Create the Scraper Service

Create `internal/services/scraper.go`:

```go
package services

import (
    "fmt"
    "net/http"
    "strings"
    "time"
    "clank/internal/models"
    
    "github.com/PuerkitoBio/goquery"
)

type ScraperService struct {
    client *http.Client
}

func NewScraperService() *ScraperService {
    return &ScraperService{
        client: &http.Client{
            Timeout: 30 * time.Second,
        },
    }
}

func (s *ScraperService) ScrapeArticle(url string) (*models.ArticleContent, error) {
    resp, err := s.client.Get(url)
    if err != nil {
        return nil, fmt.Errorf("failed to fetch URL: %w", err)
    }
    defer resp.Body.Close()

    doc, err := goquery.NewDocumentFromReader(resp.Body)
    if err != nil {
        return nil, fmt.Errorf("failed to parse HTML: %w", err)
    }

    article := &models.ArticleContent{
        URL: url,
    }

    // Extract title
    doc.Find("h1, .headline, .title").First().Each(func(i int, s *goquery.Selection) {
        if article.Title == "" {
            article.Title = strings.TrimSpace(s.Text())
        }
    })

    // Extract content
    var contentParts []string
    doc.Find("p, .content p, .article-body p, .story-body p").Each(func(i int, s *goquery.Selection) {
        text := strings.TrimSpace(s.Text())
        if text != "" && len(text) > 20 { // Filter out very short paragraphs
            contentParts = append(contentParts, text)
        }
    })
    article.Content = strings.Join(contentParts, "\n\n")

    // Extract author
    doc.Find(".author, .byline, [rel='author']").First().Each(func(i int, s *goquery.Selection) {
        article.Author = strings.TrimSpace(s.Text())
    })

    // Extract date
    doc.Find("time, .date, .publish-date").First().Each(func(i int, s *goquery.Selection) {
        if datetime, exists := s.Attr("datetime"); exists {
            article.Date = datetime
        } else {
            article.Date = strings.TrimSpace(s.Text())
        }
    })

    if article.Content == "" {
        return nil, fmt.Errorf("no content extracted from URL")
    }

    return article, nil
}
```

### 3. Create the Extraction Service

Create `internal/services/extraction.go`:

```go
package services

import (
    "context"
    "encoding/json"
    "fmt"
    "strings"
    "time"
    "clank/internal/llm"
    "clank/internal/models"
)

type ExtractionService struct {
    llmClient *llm.Client
    scraper   *ScraperService
}

func NewExtractionService(llmClient *llm.Client) *ExtractionService {
    return &ExtractionService{
        llmClient: llmClient,
        scraper:   NewScraperService(),
    }
}

func (s *ExtractionService) ExtractFromArticle(ctx context.Context, req *models.ArticleExtractionRequest) (*models.ArticleExtractionResponse, error) {
    var article *models.ArticleContent
    var err error

    // Get article content
    if req.URL != "" {
        article, err = s.scraper.ScrapeArticle(req.URL)
        if err != nil {
            return nil, fmt.Errorf("failed to scrape article: %w", err)
        }
    } else if req.Content != "" {
        article = &models.ArticleContent{
            Title:   req.Title,
            Content: req.Content,
        }
    } else {
        return nil, fmt.Errorf("either URL or content must be provided")
    }

    // Default entity types if not specified
    entityTypes := req.EntityTypes
    if len(entityTypes) == 0 {
        entityTypes = []string{"Person", "Organization", "Location", "Event", "Money", "Date"}
    }

    // Create extraction prompt
    extractionPrompt := s.buildExtractionPrompt(article, entityTypes)

    // Send to LLM
    messages := []llm.Message{
        {
            Role:    "system",
            Content: "You are an expert entity extraction system. Extract entities and relationships from news articles with high accuracy. Return valid JSON only.",
        },
        {
            Role:    "user",
            Content: extractionPrompt,
        },
    }

    result, err := s.llmClient.Generate(ctx, messages)
    if err != nil {
        return nil, fmt.Errorf("failed to process with LLM: %w", err)
    }

    // Parse LLM response
    var extraction struct {
        Entities      []models.ExtractedEntity       `json:"entities"`
        Relationships []models.ExtractedRelationship `json:"relationships"`
        Confidence    float64                        `json:"confidence"`
    }

    llmContent := result.Choices[0].Message.Content
    // Clean up the response to extract JSON
    if start := strings.Index(llmContent, "{"); start != -1 {
        if end := strings.LastIndex(llmContent, "}"); end != -1 {
            llmContent = llmContent[start : end+1]
        }
    }

    if err := json.Unmarshal([]byte(llmContent), &extraction); err != nil {
        return nil, fmt.Errorf("failed to parse LLM response: %w, content: %s", err, llmContent)
    }

    response := &models.ArticleExtractionResponse{
        Article:       *article,
        Entities:      extraction.Entities,
        Relationships: extraction.Relationships,
        ProcessedAt:   time.Now(),
        Confidence:    extraction.Confidence,
    }

    return response, nil
}

func (s *ExtractionService) buildExtractionPrompt(article *models.ArticleContent, entityTypes []string) string {
    return fmt.Sprintf(`
Extract entities and relationships from this news article.

Title: %s
Content: %s

Entity Types to Extract: %s

Instructions:
1. Extract all mentioned entities of the specified types
2. Identify relationships between entities
3. Include confidence scores (0.0-1.0)
4. Include source text spans where entities were found
5. For relationships, include contextual information

Return ONLY valid JSON in this exact format:
{
  "entities": [
    {
      "name": "Entity Name",
      "type": "Person|Organization|Location|Event|Money|Date",
      "properties": {
        "additional_info": "value"
      },
      "confidence": 0.95,
      "source_span": "exact text from article"
    }
  ],
  "relationships": [
    {
      "from": "Entity1 Name",
      "to": "Entity2 Name", 
      "type": "WORKS_FOR|LOCATED_IN|PARTICIPATED_IN|DONATED_TO|etc",
      "properties": {
        "amount": "if applicable",
        "date": "if mentioned"
      },
      "confidence": 0.90,
      "context": "surrounding context from article"
    }
  ],
  "confidence": 0.85
}
`, article.Title, article.Content, strings.Join(entityTypes, ", "))
}
```

### 4. Create the Handler

Create `internal/api/handlers/extraction.go`:

```go
package handlers

import (
    "net/http"
    "clank/config"
    "clank/internal/llm"
    "clank/internal/models"
    "clank/internal/services"
    "clank/internal/db"
    "github.com/gin-gonic/gin"
    "github.com/neo4j/neo4j-go-driver/v4/neo4j"
)

type ExtractionHandler struct {
    extractionService *services.ExtractionService
}

func NewExtractionHandler(cfg *config.Config) *ExtractionHandler {
    llmClient := llm.NewClient(cfg)
    extractionService := services.NewExtractionService(llmClient)
    
    return &ExtractionHandler{
        extractionService: extractionService,
    }
}

// ExtractEntities extracts entities from a news article
func (h *ExtractionHandler) ExtractEntities(c *gin.Context) {
    var req models.ArticleExtractionRequest
    if err := c.ShouldBindJSON(&req); err != nil {
        c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
        return
    }

    result, err := h.extractionService.ExtractFromArticle(c.Request.Context(), &req)
    if err != nil {
        c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
        return
    }

    c.JSON(http.StatusOK, result)
}

// ExtractAndStore extracts entities and stores them in the graph database
func (h *ExtractionHandler) ExtractAndStore(c *gin.Context) {
    var req models.ArticleExtractionRequest
    if err := c.ShouldBindJSON(&req); err != nil {
        c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
        return
    }

    // Extract entities
    result, err := h.extractionService.ExtractFromArticle(c.Request.Context(), &req)
    if err != nil {
        c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
        return
    }

    // Store in graph database
    storedNodes, storedRels, err := h.storeExtractionResults(result)
    if err != nil {
        c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to store results: " + err.Error()})
        return
    }

    response := gin.H{
        "extraction": result,
        "stored": gin.H{
            "nodes":         storedNodes,
            "relationships": storedRels,
        },
    }

    c.JSON(http.StatusCreated, response)
}

func (h *ExtractionHandler) storeExtractionResults(result *models.ArticleExtractionResponse) ([]models.Node, []models.Relationship, error) {
    var storedNodes []models.Node
    var storedRels []models.Relationship

    // Store entities as nodes
    _, err := db.ExecuteWrite(func(tx neo4j.Transaction) (interface{}, error) {
        for _, entity := range result.Entities {
            // Create node
            query := `
                MERGE (n:%s {name: $name})
                ON CREATE SET n += $properties, n.created_at = datetime(), n.source_article = $article_url
                ON MATCH SET n += $properties, n.updated_at = datetime()
                RETURN n
            `
            
            properties := entity.Properties
            if properties == nil {
                properties = make(map[string]interface{})
            }
            properties["confidence"] = entity.Confidence
            properties["source_span"] = entity.SourceSpan

            params := map[string]interface{}{
                "name":        entity.Name,
                "properties":  properties,
                "article_url": result.Article.URL,
            }

            nodeResult, err := tx.Run(fmt.Sprintf(query, entity.Type), params)
            if err != nil {
                return nil, fmt.Errorf("failed to create node for entity %s: %w", entity.Name, err)
            }

            if nodeResult.Next() {
                record := nodeResult.Record()
                node := record.Values[0].(neo4j.Node)
                
                storedNodes = append(storedNodes, models.Node{
                    ID:    fmt.Sprint(node.Id),
                    Type:  entity.Type,
                    Props: node.Props,
                })
            }
        }

        return nil, nil
    })

    if err != nil {
        return nil, nil, err
    }

    // Store relationships
    _, err = db.ExecuteWrite(func(tx neo4j.Transaction) (interface{}, error) {
        for _, rel := range result.Relationships {
            query := `
                MATCH (from {name: $fromName}), (to {name: $toName})
                MERGE (from)-[r:%s]->(to)
                ON CREATE SET r += $properties, r.created_at = datetime(), r.source_article = $article_url
                ON MATCH SET r += $properties, r.updated_at = datetime()
                RETURN r
            `

            properties := rel.Properties
            if properties == nil {
                properties = make(map[string]interface{})
            }
            properties["confidence"] = rel.Confidence
            properties["context"] = rel.Context

            params := map[string]interface{}{
                "fromName":    rel.From,
                "toName":      rel.To,
                "properties":  properties,
                "article_url": result.Article.URL,
            }

            relResult, err := tx.Run(fmt.Sprintf(query, rel.Type), params)
            if err != nil {
                return nil, fmt.Errorf("failed to create relationship %s->%s: %w", rel.From, rel.To, err)
            }

            if relResult.Next() {
                record := relResult.Record()
                relationship := record.Values[0].(neo4j.Relationship)
                
                storedRels = append(storedRels, models.Relationship{
                    ID:     fmt.Sprint(relationship.Id),
                    FromID: fmt.Sprint(relationship.StartId),
                    ToID:   fmt.Sprint(relationship.EndId),
                    Type:   relationship.Type,
                    Props:  relationship.Props,
                })
            }
        }

        return nil, nil
    })

    return storedNodes, storedRels, err
}
```

### 5. Update Router

Add to `internal/api/routes/router.go`:

```go
func SetupRouter() *gin.Engine {
    r := gin.Default()
    cfg := config.LoadConfig()

    // ... existing middleware and routes ...

    // Extraction endpoints
    extractionHandler := handlers.NewExtractionHandler(cfg)
    extraction := r.Group("/api/extraction")
    {
        extraction.POST("/analyze", extractionHandler.ExtractEntities)
        extraction.POST("/analyze-and-store", extractionHandler.ExtractAndStore)
    }

    return r
}
```

### 6. Usage Examples

#### Extract entities from URL:
```bash
curl -X POST http://localhost:8080/api/extraction/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://example.com/news-article",
    "entity_types": ["Person", "Organization", "Location", "Money"]
  }'
```

#### Extract and store in graph:
```bash
curl -X POST http://localhost:8080/api/extraction/analyze-and-store \
  -H "Content-Type: application/json" \
  -d '{
    "content": "John Doe, CEO of TechCorp, announced a $10M investment in AI research at their San Francisco headquarters.",
    "title": "TechCorp Announces Major AI Investment",
    "entity_types": ["Person", "Organization", "Location", "Money", "Event"]
  }'
```

## MCP Tool Integration Workflow

### Quick Start: Adding a New MCP Tool

1. **Define the tool** in `internal/mcp/tools.go`
2. **Implement the handler** function
3. **Register the tool** in `NewMCPService()`
4. **Test via MCP chat endpoint**

### Example: Adding a Web Scraping Tool

#### 1. Add Tool Definition

```go
// In internal/mcp/tools.go
func (s *MCPService) RegisterWebScrapingTool() {
    s.server.RegisterTool(&mcp.Tool{
        Name: "scrape_webpage",
        Description: "Scrape content from a webpage and extract relevant information",
        InputSchema: map[string]interface{}{
            "type": "object",
            "properties": map[string]interface{}{
                "url": {
                    "type": "string",
                    "description": "The URL to scrape",
                },
                "extract_type": {
                    "type": "string", 
                    "enum": []string{"article", "entities", "links", "all"},
                    "description": "What type of information to extract",
                },
                "save_to_graph": {
                    "type": "boolean",
                    "description": "Whether to save extracted entities to the graph database",
                    "default": false,
                },
            },
            "required": []string{"url"},
        },
    }, s.handleWebScraping)
}
```

#### 2. Implement Handler

```go
func (s *MCPService) handleWebScraping(ctx context.Context, params map[string]interface{}) (interface{}, error) {
    url := params["url"].(string)
    extractType := params["extract_type"]
    if extractType == nil {
        extractType = "article"
    }
    
    saveToGraph := false
    if save, ok := params["save_to_graph"].(bool); ok {
        saveToGraph = save
    }
    
    // Use the scraper service
    scraperService := services.NewScraperService()
    article, err := scraperService.ScrapeArticle(url)
    if err != nil {
        return nil, fmt.Errorf("failed to scrape URL: %w", err)
    }
    
    result := map[string]interface{}{
        "article": article,
    }
    
    // If entities extraction is requested
    if extractType == "entities" || extractType == "all" {
        extractionService := services.NewExtractionService(s.llmClient)
        extractionReq := &models.ArticleExtractionRequest{
            Content: article.Content,
            Title:   article.Title,
        }
        
        extraction, err := extractionService.ExtractFromArticle(ctx, extractionReq)
        if err != nil {
            return nil, fmt.Errorf("failed to extract entities: %w", err)
        }
        
        result["entities"] = extraction.Entities
        result["relationships"] = extraction.Relationships
        
        // Save to graph if requested
        if saveToGraph {
            // Implementation for saving to graph...
            result["saved_to_graph"] = true
        }
    }
    
    return result, nil
}
```

#### 3. Register in MCP Service

```go
func NewMCPService(cfg *config.Config) *MCPService {
    service := &MCPService{
        llmClient: llm.NewClient(cfg),
    }

    impl := &mcp.Implementation{
        Name:    "clank-llm-proxy", 
        Version: "v0.1.0",
    }

    service.server = mcp.NewServer(impl, &mcp.ServerOptions{})
    
    // Register all tools
    service.RegisterTools()
    service.RegisterWebScrapingTool() // Add this line

    return service
}
```

#### 4. Test the Tool

```bash
# Via MCP chat endpoint
curl -X POST http://localhost:8080/llm/chat/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {
        "role": "user", 
        "content": "Please scrape https://example.com/news and extract entities, then save them to the graph database"
      }
    ],
    "stream": false
  }'
```

## Advanced MCP Patterns

### Context Injection

The MCP service can inject graph context based on conversation history:

```go
func (s *MCPService) ProcessWithMCP(ctx context.Context, messages []llm.Message) ([]llm.Message, error) {
    // Analyze the conversation for entity mentions
    entities := s.extractMentionedEntities(messages)
    
    // Get relevant context from graph
    var contextMessages []llm.Message
    for _, entity := range entities {
        subgraph, err := s.getEntityContext(entity)
        if err != nil {
            continue
        }
        
        contextMsg := llm.Message{
            Role: "system",
            Content: fmt.Sprintf("Context for %s: %s", entity, subgraph),
        }
        contextMessages = append(contextMessages, contextMsg)
    }
    
    // Combine context with original messages
    processedMessages := append(contextMessages, messages...)
    
    return processedMessages, nil
}
```

### Tool Chaining

MCP tools can call other tools to create complex workflows:

```go
func (s *MCPService) handleComplexAnalysis(ctx context.Context, params map[string]interface{}) (interface{}, error) {
    // Step 1: Scrape article
    scrapeResult, err := s.handleWebScraping(ctx, map[string]interface{}{
        "url": params["url"],
        "extract_type": "entities",
    })
    if err != nil {
        return nil, err
    }
    
    // Step 2: Analyze corruption indicators
    entities := scrapeResult.(map[string]interface{})["entities"]
    corruptionResult, err := s.handleCorruptionAnalysis(ctx, map[string]interface{}{
        "entities": entities,
    })
    if err != nil {
        return nil, err
    }
    
    // Step 3: Find related entities in graph
    graphResult, err := s.handleGraphQuery(ctx, map[string]interface{}{
        "query": "Find entities connected to suspicious activities",
    })
    if err != nil {
        return nil, err
    }
    
    return map[string]interface{}{
        "scrape_result": scrapeResult,
        "corruption_analysis": corruptionResult,
        "related_entities": graphResult,
    }, nil
}
```

## Configuration

### Environment Variables

```bash
# LLM Configuration
LLM_URL=http://localhost:8080
LLM_MODEL=llama-2-7b-chat
LLM_TIMEOUT=300s

# Database Configuration  
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password

# Server Configuration
SERVER_PORT=8080
SERVER_HOST=0.0.0.0

# MCP Configuration
MCP_ENABLED=true
MCP_TOOLS_ENABLED=entity_extraction,graph_query,web_scraping
```

### Configuration File

Create `config/config.yaml`:

```yaml
server:
  host: "0.0.0.0"
  port: 8080

llm:
  url: "http://localhost:8080"
  model: "llama-2-7b-chat"  
  timeout: "300s"

database:
  uri: "bolt://localhost:7687"
  username: "neo4j"
  password: "password"

mcp:
  enabled: true
  tools:
    - entity_extraction
    - graph_query  
    - web_scraping
    - corruption_analysis
    
extraction:
  default_entity_types:
    - Person
    - Organization
    - Location
    - Event
    - Money
    - Date
  confidence_threshold: 0.7
  max_article_length: 50000
```

## Error Handling

The API uses standard HTTP status codes:

- `200` - Success
- `201` - Created  
- `204` - No Content
- `400` - Bad Request
- `404` - Not Found
- `409` - Conflict
- `500` - Internal Server Error
- `503` - Service Unavailable

Error responses follow this format:

```json
{
  "error": "Description of the error",
  "code": "ERROR_CODE",
  "details": "Additional details if available"
}
```

## Rate Limiting

The API implements rate limiting for expensive operations:

- LLM requests: 10 requests/minute per IP
- Graph queries: 100 requests/minute per IP
- Extraction requests: 5 requests/minute per IP

## Authentication

Currently, the API runs without authentication. To add authentication:

1. **Create middleware** in `internal/api/middleware/auth.go`
2. **Add JWT token validation**
3. **Apply to protected routes**

```go
func RequireAuth() gin.HandlerFunc {
    return func(c *gin.Context) {
        token := c.GetHeader("Authorization")
        if token == "" {
            c.JSON(http.StatusUnauthorized, gin.H{"error": "Authorization header required"})
            c.Abort()
            return
        }
        
        // Validate JWT token
        // ...
        
        c.Next()
    }
}
```

## Testing

### Unit Tests

Run unit tests:

```bash
go test ./...
```

### Integration Tests

Test with real services:

```bash
# Start Neo4j and llama.cpp first
docker run -p 7687:7687 -p 7474:7474 neo4j:latest
./llama.cpp/server -m model.gguf --host 0.0.0.0 --port 8080

# Run integration tests
go test ./internal/api/handlers -tags=integration
```

### API Testing

Use the provided Postman collection or curl commands:

```bash
# Test health endpoint
curl http://localhost:8080/health

# Test entity extraction
curl -X POST http://localhost:8080/api/extraction/analyze \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com/article"}'
```

## Deployment

### Docker Deployment

Create `Dockerfile`:

```dockerfile
FROM golang:1.21-alpine AS builder

WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download

COPY . .
RUN go build -o clank-backend ./cmd/server

FROM alpine:latest
RUN apk --no-cache add ca-certificates
WORKDIR /root/

COPY --from=builder /app/clank-backend .
COPY --from=builder /app/config ./config

EXPOSE 8080
CMD ["./clank-backend"]
```

Create `docker-compose.yml`:

```yaml
version: '3.8'

services:
  clank-backend:
    build: .
    ports:
      - "8080:8080"
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - LLM_URL=http://llama-cpp:8080
    depends_on:
      - neo4j
      - llama-cpp

  neo4j:
    image: neo4j:5.15
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      - NEO4J_AUTH=neo4j/password
    volumes:
      - neo4j_data:/data

  llama-cpp:
    image: ghcr.io/ggerganov/llama.cpp:server
    ports:
      - "8081:8080"
    volumes:
      - ./models:/models
    command: >
      --model /models/llama-2-7b-chat.gguf 
      --host 0.0.0.0 
      --port 8080

volumes:
  neo4j_data:
```

Deploy:

```bash
docker-compose up -d
```

## Monitoring and Logging

### Structured Logging

The application uses structured logging. Logs include:

- Request/response details
- LLM processing times
- Database operation metrics
- Error traces

### Metrics

Key metrics to monitor:

- Request latency
- LLM response times  
- Database connection pool status
- Memory usage
- Error rates

### Health Checks

The `/health` endpoint provides comprehensive health information:

- Service status
- Database connectivity
- LLM availability
- System resources

## Contributing

To contribute to the project:

1. **Fork the repository**
2. **Create a feature branch**
3. **Add tests for new functionality**
4. **Update documentation**
5. **Submit a pull request**

### Code Style

- Use `gofmt` for code formatting
- Follow Go naming conventions
- Add comments for exported functions
- Keep functions small and focused
- Use dependency injection

### Adding New Features

When adding new features:

1. **Design the API first** - define endpoints and data structures
2. **Create models** - define the data structures in `internal/models/`
3. **Implement services** - business logic in `internal/services/`
4. **Create handlers** - API handlers in `internal/api/handlers/`
5. **Update router** - add routes in `internal/api/routes/`
6. **Add tests** - unit and integration tests
7. **Update documentation** - update this API documentation

This completes the comprehensive API documentation for your Clank backend system. The document covers everything from basic usage to advanced MCP integration patterns, with a complete example of building an entity extraction endpoint from scratch.